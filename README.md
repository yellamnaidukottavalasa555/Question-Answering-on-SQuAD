# Question-Answering-on-SQuAD-Dataset

This project aimed to explore the effectiveness of using the DistilBERT-base-uncased-distilled-squad, ALBERT-base-v2, Google/ELECTRA-base-generator models on the Stanford SQUAD dataset for question answering tasks. The objective was to achieve a high F1 score to demonstrate the potential impact of these models in natural language processing. The results of the DistilBERT-base-uncased-distilled-squad model showed a significant improvement in F1 score, with a final score of 84.19. These findings indicate that this model is highly effective for question answering tasks and have the potential to improve the accuracy of natural language processing systems.
